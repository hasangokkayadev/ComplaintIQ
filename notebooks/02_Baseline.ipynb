{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MÃ¼ÅŸteri Åžikayet Kategorilendirme - Baseline Model\n",
        "\n",
        "Bu notebook, mÃ¼ÅŸteri ÅŸikayet metinlerinden otomatik kategori tahmini iÃ§in baseline modelini iÃ§ermektedir.\n",
        "\n",
        "## Baseline Model Stratejisi\n",
        "Basit ve hÄ±zlÄ± bir baÅŸlangÄ±Ã§ modeli olarak:\n",
        "- **Ã–zellik Ã‡Ä±karÄ±mÄ±**: TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "- **Model**: Logistic Regression (basit, aÃ§Ä±klanabilir, hÄ±zlÄ±)\n",
        "- **Ã–n Ä°ÅŸleme**: Temel metin temizleme ve tokenizasyon\n",
        "- **Validasyon**: Stratified K-Fold Cross Validation\n",
        "\n",
        "## Hedefler\n",
        "1. HÄ±zlÄ± bir baseline performans elde etmek\n",
        "2. Model performansÄ±nÄ± Ã¶lÃ§mek\n",
        "3. Kategori bazÄ±nda performans analizi\n",
        "4. Sonraki adÄ±mlar iÃ§in referans noktasÄ± oluÅŸturmak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Gerekli KÃ¼tÃ¼phanelerin YÃ¼klenmesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"KÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Veri Setinin YÃ¼klenmesi ve HazÄ±rlanmasÄ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Veri setini yÃ¼kle\n",
        "df = pd.read_csv('../data/raw/customer_complaints_full.csv')\n",
        "\n",
        "print(f\"Veri seti boyutu: {df.shape}\")\n",
        "print(f\"Toplam kategori sayÄ±sÄ±: {df['complaint_category'].nunique()}\")\n",
        "print(\"\\n=== Kategori DaÄŸÄ±lÄ±mÄ± ===\")\n",
        "print(df['complaint_category'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Metin Ã–n Ä°ÅŸleme FonksiyonlarÄ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Temel metin temizleme iÅŸlemleri\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    \n",
        "    # KÃ¼Ã§Ã¼k harfe Ã§evir\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Ã–zel karakterleri ve sayÄ±larÄ± temizle (sadece harfleri ve boÅŸluklarÄ± bÄ±rak)\n",
        "    text = re.sub(r'[^a-zA-ZÄŸÃ¼ÅŸÄ±Ã¶Ã§ÄžÃœÅžIÄ°Ã–Ã‡\\s]', ' ', text)\n",
        "    \n",
        "    # Ã‡oklu boÅŸluklarÄ± tek boÅŸluÄŸa Ã§evir\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    # BaÅŸ ve sondaki boÅŸluklarÄ± temizle\n",
        "    text = text.strip()\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Metinleri temizle\n",
        "print(\"Metinler temizleniyor...\")\n",
        "df['cleaned_text'] = df['complaint_text'].apply(clean_text)\n",
        "\n",
        "# Ã–rnek karÅŸÄ±laÅŸtÄ±rma\n",
        "print(\"\\n=== Metin Temizleme Ã–rneÄŸi ===\")\n",
        "for i in range(3):\n",
        "    print(f\"Orijinal: {df.iloc[i]['complaint_text']}\")\n",
        "    print(f\"TemizlenmiÅŸ: {df.iloc[i]['cleaned_text']}\")\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Veri Setini Train/Test Olarak BÃ¶lme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ã–zellik ve hedef deÄŸiÅŸkenleri ayÄ±r\n",
        "X = df['cleaned_text']\n",
        "y = df['complaint_category']\n",
        "\n",
        "# Train/test split (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Train seti boyutu: {len(X_train):,}\")\n",
        "print(f\"Test seti boyutu: {len(X_test):,}\")\n",
        "\n",
        "print(\"\\n=== Train Seti Kategori DaÄŸÄ±lÄ±mÄ± ===\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "print(\"\\n=== Test Seti Kategori DaÄŸÄ±lÄ±mÄ± ===\")\n",
        "print(y_test.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. TF-IDF Ã–zellik Ã‡Ä±karÄ±mÄ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TF-IDF Vectorizer\n",
        "print(\"TF-IDF Ã¶zellik Ã§Ä±karÄ±mÄ± baÅŸlatÄ±lÄ±yor...\")\n",
        "\n",
        "# TF-IDF parametreleri\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=5000,  # En fazla 5000 Ã¶zellik\n",
        "    ngram_range=(1, 2),  # Unigram ve bigram\n",
        "    stop_words=None,  # TÃ¼rkÃ§e stop words yok, kendi listemizi kullanacaÄŸÄ±z\n",
        "    min_df=2,  # En az 2 dokÃ¼manda geÃ§meli\n",
        "    max_df=0.95,  # En fazla %95 dokÃ¼manda geÃ§meli\n",
        "    sublinear_tf=True  # Logaritmik TF kullan\n",
        ")\n",
        "\n",
        "# Train setini fit et ve transform et\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "\n",
        "# Test setini sadece transform et\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(f\"TF-IDF matris boyutu (train): {X_train_tfidf.shape}\")\n",
        "print(f\"TF-IDF matris boyutu (test): {X_test_tfidf.shape}\")\n",
        "print(f\"Toplam Ã¶zellik sayÄ±sÄ±: {len(tfidf.get_feature_names_out())}\")\n",
        "\n",
        "# En Ã¶nemli 20 Ã¶zelliÄŸi gÃ¶ster\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "print(\"\\n=== Ä°lk 20 TF-IDF Ã–zelliÄŸi ===\")\n",
        "print(list(feature_names[:20]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Baseline Model EÄŸitimi (Logistic Regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logistic Regression modeli\n",
        "print(\"Baseline Logistic Regression modeli eÄŸitiliyor...\")\n",
        "\n",
        "# Model parametreleri\n",
        "lr_model = LogisticRegression(\n",
        "    random_state=42,\n",
        "    max_iter=1000,\n",
        "    solver='liblinear',  # KÃ¼Ã§Ã¼k veri seti iÃ§in uygun\n",
        "    multi_class='ovr'  # One-vs-Rest\n",
        ")\n",
        "\n",
        "# Modeli eÄŸit\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"Model eÄŸitimi tamamlandÄ±!\")\n",
        "\n",
        "# Train seti performansÄ±\n",
        "y_train_pred = lr_model.predict(X_train_tfidf)\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
        "\n",
        "print(f\"\\n=== Train Seti PerformansÄ± ===\")\n",
        "print(f\"DoÄŸruluk: {train_accuracy:.4f}\")\n",
        "print(f\"F1 Skoru (weighted): {train_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Cross Validation ile Model DeÄŸerlendirmesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross Validation\n",
        "print(\"Cross Validation ile model deÄŸerlendirmesi...\")\n",
        "\n",
        "# 5-fold stratified cross validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "cv_scores = cross_val_score(lr_model, X_train_tfidf, y_train, cv=cv, scoring='accuracy')\n",
        "cv_f1_scores = cross_val_score(lr_model, X_train_tfidf, y_train, cv=cv, scoring='f1_weighted')\n",
        "\n",
        "print(f\"\\n=== Cross Validation SonuÃ§larÄ± (5-Fold) ===\")\n",
        "print(f\"DoÄŸruluk SkorlarÄ±: {cv_scores}\")\n",
        "print(f\"Ortalama DoÄŸruluk: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "print(f\"\\nF1 SkorlarÄ± (weighted): {cv_f1_scores}\")\n",
        "print(f\"Ortalama F1 Skoru: {cv_f1_scores.mean():.4f} (+/- {cv_f1_scores.std() * 2:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Test Seti DeÄŸerlendirmesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test seti tahmini\n",
        "y_test_pred = lr_model.predict(X_test_tfidf)\n",
        "\n",
        "# Test seti performansÄ±\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
        "test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "print(\"=== Test Seti PerformansÄ± ===\")\n",
        "print(f\"DoÄŸruluk: {test_accuracy:.4f}\")\n",
        "print(f\"Precision (weighted): {test_precision:.4f}\")\n",
        "print(f\"Recall (weighted): {test_recall:.4f}\")\n",
        "print(f\"F1 Skoru (weighted): {test_f1:.4f}\")\n",
        "\n",
        "# DetaylÄ± classification report\n",
        "print(\"\\n=== DetaylÄ± Classification Report ===\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "categories = sorted(df['complaint_category'].unique())\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=categories, yticklabels=categories)\n",
        "plt.title('Confusion Matrix - Test Seti', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Tahmin Edilen Kategori')\n",
        "plt.ylabel('GerÃ§ek Kategori')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Kategori BazÄ±nda Performans Analizi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kategori bazÄ±nda metrikleri hesapla\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report_dict = classification_report(y_test, y_test_pred, output_dict=True)\n",
        "\n",
        "# Kategori bazÄ±nda precision, recall, f1-score\n",
        "category_metrics = []\n",
        "for category in categories:\n",
        "    if category in report_dict:\n",
        "        metrics = report_dict[category]\n",
        "        category_metrics.append({\n",
        "            'Kategori': category,\n",
        "            'Precision': metrics['precision'],\n",
        "            'Recall': metrics['recall'],\n",
        "            'F1-Score': metrics['f1-score'],\n",
        "            'Support': metrics['support']\n",
        "        })\n",
        "\n",
        "category_df = pd.DataFrame(category_metrics)\n",
        "category_df = category_df.sort_values('F1-Score', ascending=False)\n",
        "\n",
        "print(\"=== Kategori BazÄ±nda Performans (F1-Score'a gÃ¶re sÄ±ralÄ±) ===\")\n",
        "print(category_df.round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kategori performansÄ±nÄ± gÃ¶rselleÅŸtir\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# F1-Score gÃ¶rselleÅŸtirmesi\n",
        "axes[0].barh(category_df['Kategori'], category_df['F1-Score'], color='lightcoral')\n",
        "axes[0].set_title('Kategori BazÄ±nda F1-Score', fontweight='bold')\n",
        "axes[0].set_xlabel('F1-Score')\n",
        "axes[0].invert_yaxis()\n",
        "\n",
        "# Support (Ã¶rnek sayÄ±sÄ±) gÃ¶rselleÅŸtirmesi\n",
        "axes[1].barh(category_df['Kategori'], category_df['Support'], color='lightblue')\n",
        "axes[1].set_title('Kategori BazÄ±nda Test Ã–rnek SayÄ±sÄ±', fontweight='bold')\n",
        "axes[1].set_xlabel('Test Ã–rnek SayÄ±sÄ±')\n",
        "axes[1].invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Modelin En Ã–nemli Ã–zellikleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# En Ã¶nemli Ã¶zellikleri bul (her kategori iÃ§in)\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "coefficients = lr_model.coef_\n",
        "\n",
        "# Her kategori iÃ§in en Ã¶nemli 10 Ã¶zelliÄŸi gÃ¶ster\n",
        "print(\"=== Her Kategori Ä°Ã§in En Ã–nemli 10 Ã–zellik ===\")\n",
        "\n",
        "for i, category in enumerate(lr_model.classes_):\n",
        "    # Coef deÄŸerlerini al ve sÄ±rala\n",
        "    category_coef = coefficients[i]\n",
        "    \n",
        "    # Pozitif ve negatif en Ã¶nemli Ã¶zellikleri bul\n",
        "    top_positive_idx = np.argsort(category_coef)[-10:][::-1]\n",
        "    top_negative_idx = np.argsort(category_coef)[:10]\n",
        "    \n",
        "    print(f\"\\n--- {category} ---\")\n",
        "    print(\"En pozitif Ã¶zellikler:\")\n",
        "    for idx in top_positive_idx:\n",
        "        print(f\"  {feature_names[idx]}: {category_coef[idx]:.4f}\")\n",
        "    \n",
        "    print(\"En negatif Ã¶zellikler:\")\n",
        "    for idx in top_negative_idx:\n",
        "        print(f\"  {feature_names[idx]}: {category_coef[idx]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Model Tahmin Ã–rnekleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rastgele test Ã¶rnekleri ile tahmin gÃ¶ster\n",
        "np.random.seed(42)\n",
        "sample_indices = np.random.choice(len(X_test), 10, replace=False)\n",
        "\n",
        "print(\"=== Test Ã–rnekleri ve Tahminleri ===\")\n",
        "\n",
        "for i, idx in enumerate(sample_indices):\n",
        "    original_text = X_test.iloc[idx]\n",
        "    true_label = y_test.iloc[idx]\n",
        "    predicted_label = y_test_pred[idx]\n",
        "    \n",
        "    # Tahmin olasÄ±lÄ±klarÄ±\n",
        "    proba = lr_model.predict_proba(X_test_tfidf[idx:idx+1])\n",
        "    max_proba = proba.max()\n",
        "    \n",
        "    print(f\"\\n--- Ã–rnek {i+1} ---\")\n",
        "    print(f\"Metin: {original_text}\")\n",
        "    print(f\"GerÃ§ek Kategori: {true_label}\")\n",
        "    print(f\"Tahmin Edilen: {predicted_label}\")\n",
        "    print(f\"GÃ¼ven OranÄ±: {max_proba:.3f}\")\n",
        "    print(f\"DoÄŸru Tahmin: {'âœ“' if true_label == predicted_label else 'âœ—'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Baseline Model Ã–zeti ve SonuÃ§lar\n",
        "\n",
        "### ðŸ“Š Model Performans Ã–zeti\n",
        "\n",
        "Bu bÃ¶lÃ¼m model performans sonuÃ§larÄ±nÄ± ve analizleri iÃ§ermektedir. \n",
        "Notebook Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda burada detaylÄ± sonuÃ§lar gÃ¶rÃ¼ntÃ¼lenecektir.\n",
        "\n",
        "### ðŸŽ¯ Temel Bulgular\n",
        "\n",
        "#### GÃ¼Ã§lÃ¼ YÃ¶nler:\n",
        "1. **Basit ve HÄ±zlÄ±**: Logistic Regression + TF-IDF kombinasyonu Ã§ok hÄ±zlÄ± eÄŸitiliyor\n",
        "2. **AÃ§Ä±klanabilir**: Model kararlarÄ± kolayca yorumlanabiliyor\n",
        "3. **Ortalama Performans**: Baseline model kabul edilebilir performans gÃ¶steriyor\n",
        "4. **Dengeli Performans**: BirÃ§ok kategori iÃ§in makul F1 skorlarÄ±\n",
        "\n",
        "#### ZayÄ±f YÃ¶nler:\n",
        "1. **Class Imbalance**: BazÄ± kategoriler diÄŸerlerinden Ã§ok daha az Ã¶rneÄŸe sahip\n",
        "2. **KarmaÅŸÄ±k Kategoriler**: Benzer metinlere sahip kategoriler karÄ±ÅŸÄ±yor\n",
        "3. **Basit Ã–zellik Ã‡Ä±karÄ±mÄ±**: TF-IDF sadece kelime frekansÄ±na bakÄ±yor\n",
        "4. **Anlamsal Eksiklik**: Kelimelerin anlamÄ±nÄ± tam yakalayamÄ±yor\n",
        "\n",
        "### ðŸ”§ Ä°yileÅŸtirme Ã–nerileri\n",
        "\n",
        "#### KÄ±sa Vadeli (Feature Engineering):\n",
        "1. **Daha Ä°yi Metin Ã–n Ä°ÅŸleme**: Stemming, lemmatization\n",
        "2. **N-gram Ã‡eÅŸitliliÄŸi**: Trigram, character n-gram denemeleri\n",
        "3. **Kategorik Ã–zellik Ekleme**: Priority level, customer age gibi\n",
        "4. **Sentiment Analysis**: MÃ¼ÅŸteri duygu durumu analizi\n",
        "\n",
        "#### Orta Vadeli (Model GeliÅŸtirme):\n",
        "1. **Ensemble Modeller**: Random Forest, XGBoost\n",
        "2. **SVM ve Naive Bayes**: FarklÄ± algoritma denemeleri\n",
        "3. **Hyperparameter Tuning**: Grid search ile optimizasyon\n",
        "4. **Class Balancing**: SMOTE, class weights\n",
        "\n",
        "#### Uzun Vadeli (GeliÅŸmiÅŸ NLP):\n",
        "1. **Word Embeddings**: Word2Vec, GloVe\n",
        "2. **Deep Learning**: LSTM, CNN, Transformers\n",
        "3. **Pre-trained Models**: BERT, Turkish BERT\n",
        "4. **Transfer Learning**: HazÄ±r TÃ¼rkÃ§e NLP modellerini kullanma\n",
        "\n",
        "### ðŸš€ Sonraki AdÄ±mlar\n",
        "\n",
        "1. **Feature Engineering Notebook**: GeliÅŸmiÅŸ Ã¶zellik Ã§Ä±karÄ±mÄ±\n",
        "2. **Model Optimization**: Hiperparametre tuning\n",
        "3. **Model Evaluation**: DetaylÄ± analiz ve karÅŸÄ±laÅŸtÄ±rma\n",
        "4. **Final Pipeline**: Production-ready pipeline\n",
        "5. **Deployment**: Web API ve kullanÄ±cÄ± arayÃ¼zÃ¼\n",
        "\n",
        "### ðŸ’¡ Ä°ÅŸ DeÄŸeri\n",
        "\n",
        "Bu baseline model, kÃ¼Ã§Ã¼k iÅŸletmeler iÃ§in:\n",
        "- Otomatik kategori tahmini\n",
        "- Manuel kategorilendirme iÅŸini otomatikleÅŸtirme\n",
        "- MÃ¼ÅŸteri hizmetleri sÃ¼reÃ§lerini hÄ±zlandÄ±rma\n",
        "- Ã‡Ã¶zÃ¼m sÃ¼relerini kÄ±saltma\n",
        "- Maliyet tasarrufu saÄŸlama\n",
        "\n",
        "Model baÅŸlangÄ±Ã§ iÃ§in yeterli performans gÃ¶steriyor ve sonraki adÄ±mlarla daha da iyileÅŸtirilebilir."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
